### 2023-05-10

## Apache Hadoop MapReduce
- **개요**
    - Hadoop MapReduce 대규모 데이터 집합을 분산 처리하는 데 사용되는 기술이다. 이 방식은 정렬된 데이터를 분산처리(Map)하고 이를 다시 합치는(Reduce)과정을 수행한다.

        - "Map" : 입력 데이터를 키-값 쌍으로 변환하여 처리하기 쉬운 형태로 변환한다.

        - "Reduce" : Map 단계에서 생성된 결과를 병합하여 최종 결과를 만든다.

MapReduce Framework를 이용하면 대규모 분산 컴퓨팅 환경에서 대량의 데이터를 병렬처리(Distributed File System를 사용해 처리)가 가능하다.

block - 파일을 분산 저장하는 Hadoop의 기본 단위

Hadoop에서는 계산시, 큰 파일을 64MB의 block단위로 나누고 모든 block은 같은 Map 작업을 수행하고 이후 Reduce 작업(보통 한 block 단위를 별개로 처리)을 수행하게 된다.

Map과 Reduce 작업 사이에는 shuffle과 sort라는 과정이 존재한다.

- shuffle은 Map 작업이 완료된 후에 일어나는 작업으로, 각 Map Task가 생성한 출력 데이터를 파티셔닝하여 Reduce Task에게 전송하는 작업이다. 
  - 이 과정에서 Map 파티셔닝(partitioning)되어, 같은 Key를 가진 데이터는 같은 파티션(partition)으로 분류한다.

- sort는 shuffle 이후에 일어나는 작업으로, Reduce Task로 전달된 Map Data를 key를 기준으로 정렬하는 작업이다. 각 Map Task에서 정렬 후 해당 결과를 병합하여 정렬하면 같은 키를 가진 데이터는 모두 합쳐진다.

모든 Map Task가 종료되면, MapReduce 시스템은 처리된 데이터를 Reduce phase를 수행할 노드로 분산하여 전송한다. 


ex:)

<img src="https://learn.microsoft.com/ko-kr/azure/hdinsight/hadoop/media/apache-hadoop-introduction/hdi-word-count-diagram.gif">

각 데이터를 클러스터 별로 분할하여 입력 데이터에서 어떤 단어가 나오는지 파악한다.

예:) Twinkle,twinkle, little start -> {"twinkle":2,"little":1,"star":1}

- map은 입력 텍스트의 각 줄을 가져와 단어로 구분한다. 단어가 발생할 때마다 키/값 쌍을 만들어 값을 추가한다. 이 후 reduce로 보내기 전에 정렬한다.
- reduce는 각 단어의 개별 발생 수를 합산하고 단어 뒤에 발생 합계가 포함된 단일 키/값 쌍을 만든다.

Hadoop Reduce 에서는중간 산출물을 Sort하고 하나로 합쳐 Reduce Task로 생성한다. 이를 사용자 정의 Reduce 함수로 전달한다.

만들어진 결과물은 안정성을 위해 HDFS(Hadoop Distributed File System)에 저장한다.

---
Distributed File System(분산 파일 시스템)을 통해 대량의 데이터를 병렬처리 하고 있는 과정에서는

1. MapReduce 작업이 끝나면 HDFS에 파일이 써지고(write),

2. MapReduce 작업이 시작될 때는 HDFS로 부터 파일을 가져오는(Read) 작업이 수행된다.

---
### Reference
https://learn.microsoft.com/ko-kr/azure/hdinsight/hadoop/apache-hadoop-introduction

https://velog.io/@kimdukbae/MapReduce

https://eliotjang.github.io/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B3%B5%ED%95%99/Hadoop-shuffling-and-sorting-of-mapreduce-task/